{"@timestamp":"2025-08-02T14:38:28.725152059Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T14:38:29.109151304Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T14:38:29.11616749Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T14:38:34.447224716Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T14:38:34.467635308Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T14:38:34.678301214Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 50 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T14:38:37.51816704Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T14:38:37.531761853Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T14:38:39.479207054Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T14:38:39.791875643Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 2214 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T14:38:39.849062896Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T14:38:39.850102897Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T14:38:39.869621415Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.898548242Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.900108043Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.901188444Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.902574746Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.90699055Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.919806862Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.921651863Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.924176666Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.925476467Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T14:38:39.946059686Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 94 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T14:38:46.429117638Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T14:38:46.486205353Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T14:38:46.520026362Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T14:38:46.528364764Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T14:38:47.143052525Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T14:38:47.148337926Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 17783 ms"}
{"@timestamp":"2025-08-02T14:38:50.655790708Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T14:38:50.903253484Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T14:38:50.91301435Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T14:38:52.106860737Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T14:38:52.18846809Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T14:38:52.637515431Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2be95d31"}
{"@timestamp":"2025-08-02T14:38:52.642217463Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T14:38:52.853842997Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T14:38:56.604233615Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T14:38:56.969311378Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T14:39:03.075928586Z","level":"WARN","logger_name":"org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration","message":"spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning"}
{"@timestamp":"2025-08-02T14:39:04.821653439Z","level":"INFO","logger_name":"org.springframework.boot.actuate.endpoint.web.EndpointLinksResolver","message":"Exposing 14 endpoint(s) beneath base path '/actuator'"}
{"@timestamp":"2025-08-02T14:39:04.975956932Z","level":"INFO","logger_name":"org.springframework.security.web.DefaultSecurityFilterChain","message":"Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@2ce24a1a, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@26bce60d, org.springframework.security.web.context.SecurityContextHolderFilter@38c55a8a, org.springframework.security.web.header.HeaderWriterFilter@49925d21, org.springframework.security.web.authentication.logout.LogoutFilter@7404aff2, com.example.Triple_clone.common.auth.JwtAuthFilter@76eadc5a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@32d1d6c5, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@58583a2d, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@1e9d7366, org.springframework.security.web.session.SessionManagementFilter@2e0163cb, org.springframework.security.web.access.ExceptionTranslationFilter@7c048b30, org.springframework.security.web.access.intercept.AuthorizationFilter@6fc7e828]"}
{"@timestamp":"2025-08-02T14:39:06.813540212Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Starting ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T14:39:07.177303334Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat started on port(s): 8080 (http) with context path ''"}
{"@timestamp":"2025-08-02T14:39:07.330181069Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.ConsumerConfig","message":"ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = latest\n\tbootstrap.servers = [kafka:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-email-retry-group-1\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = email-retry-group\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer\n"}
{"@timestamp":"2025-08-02T14:39:08.061477917Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka version: 3.4.1"}
{"@timestamp":"2025-08-02T14:39:08.062361718Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka commitId: 8a516edc2755df89"}
{"@timestamp":"2025-08-02T14:39:08.062946618Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka startTimeMs: 1754145548055"}
{"@timestamp":"2025-08-02T14:39:08.143103989Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Subscribed to topic(s): email-retry-topic"}
{"@timestamp":"2025-08-02T14:39:08.18862933Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.ConsumerConfig","message":"ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = latest\n\tbootstrap.servers = [kafka:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-slack-retry-group-2\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = slack-retry-group\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer\n"}
{"@timestamp":"2025-08-02T14:39:08.202502142Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka version: 3.4.1"}
{"@timestamp":"2025-08-02T14:39:08.203421343Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka commitId: 8a516edc2755df89"}
{"@timestamp":"2025-08-02T14:39:08.204203143Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka startTimeMs: 1754145548202"}
{"@timestamp":"2025-08-02T14:39:08.226656363Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Subscribed to topic(s): slack-retry-topic"}
{"@timestamp":"2025-08-02T14:39:08.32443845Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Started TripleCloneApplication in 42.336 seconds (process running for 44.715)"}
{"@timestamp":"2025-08-02T14:39:08.373484493Z","level":"INFO","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"✅ Batch 프로세스 시작: 숙소 정보 크롤링","traceId":"e61dec2f-a35c-4fd7-8ac8-ddf67f029241","uri":"scheduled::ScraperBatchService.scrapeAllLocations()","email":"system"}
{"@timestamp":"2025-08-02T14:39:09.683218054Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting the last seen epoch of partition slack-retry-topic-0 to 0 since the associated topicId changed from null to HjUrRdwvQkK0Tx_sLZnRXQ"}
{"@timestamp":"2025-08-02T14:39:09.683515754Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting the last seen epoch of partition email-retry-topic-0 to 0 since the associated topicId changed from null to mQdd2KszQ1eggDw7modFew"}
{"@timestamp":"2025-08-02T14:39:09.689572159Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Cluster ID: Ob-1HD5GQPC6lHr6Ghhp_A"}
{"@timestamp":"2025-08-02T14:39:09.689502559Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Cluster ID: Ob-1HD5GQPC6lHr6Ghhp_A"}
{"@timestamp":"2025-08-02T14:39:09.693033962Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)"}
{"@timestamp":"2025-08-02T14:39:09.695819065Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)"}
{"@timestamp":"2025-08-02T14:39:09.696815466Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T14:39:09.70145467Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T14:39:09.745283409Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: need to re-join with the given member-id: consumer-slack-retry-group-2-a1bb41b2-8e63-49ce-b529-222f177eb68b"}
{"@timestamp":"2025-08-02T14:39:09.74663671Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: need to re-join with the given member-id: consumer-email-retry-group-1-71a64b06-33fe-4e83-98d2-da43d81d0574"}
{"@timestamp":"2025-08-02T14:39:09.74663711Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)"}
{"@timestamp":"2025-08-02T14:39:09.747723211Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)"}
{"@timestamp":"2025-08-02T14:39:09.747760611Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T14:39:09.748292411Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T14:39:10.816772558Z","level":"INFO","logger_name":"com.example.Triple_clone.common.logging.MetricToInfluxJob","message":"✅ Batch 프로세스 종료: InfluxDB write","traceId":"38ac43bc-dfb6-44dd-9b4c-e97bb61cd243","uri":"scheduled::MetricToInfluxJob.reportMetrics()","email":"system"}
{"@timestamp":"2025-08-02T14:39:12.755254975Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-email-retry-group-1-71a64b06-33fe-4e83-98d2-da43d81d0574', protocol='range'}"}
{"@timestamp":"2025-08-02T14:39:12.757053876Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-slack-retry-group-2-a1bb41b2-8e63-49ce-b529-222f177eb68b', protocol='range'}"}
{"@timestamp":"2025-08-02T14:39:12.760323179Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Finished assignment for group at generation 3: {consumer-email-retry-group-1-71a64b06-33fe-4e83-98d2-da43d81d0574=Assignment(partitions=[email-retry-topic-0])}"}
{"@timestamp":"2025-08-02T14:39:12.760323379Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Finished assignment for group at generation 3: {consumer-slack-retry-group-2-a1bb41b2-8e63-49ce-b529-222f177eb68b=Assignment(partitions=[slack-retry-topic-0])}"}
{"@timestamp":"2025-08-02T14:39:12.774220791Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-email-retry-group-1-71a64b06-33fe-4e83-98d2-da43d81d0574', protocol='range'}"}
{"@timestamp":"2025-08-02T14:39:12.774227191Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-slack-retry-group-2-a1bb41b2-8e63-49ce-b529-222f177eb68b', protocol='range'}"}
{"@timestamp":"2025-08-02T14:39:12.775607093Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Notifying assignor about the new Assignment(partitions=[email-retry-topic-0])"}
{"@timestamp":"2025-08-02T14:39:12.775607293Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Notifying assignor about the new Assignment(partitions=[slack-retry-topic-0])"}
{"@timestamp":"2025-08-02T14:39:12.782246699Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Adding newly assigned partitions: email-retry-topic-0"}
{"@timestamp":"2025-08-02T14:39:12.782264199Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Adding newly assigned partitions: slack-retry-topic-0"}
{"@timestamp":"2025-08-02T14:39:12.822638034Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Setting offset for partition email-retry-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}"}
{"@timestamp":"2025-08-02T14:39:12.822639134Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Setting offset for partition slack-retry-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}"}
{"@timestamp":"2025-08-02T14:39:12.825537137Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: partitions assigned: [slack-retry-topic-0]"}
{"@timestamp":"2025-08-02T14:39:12.826953838Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: partitions assigned: [email-retry-topic-0]"}
{"@timestamp":"2025-08-02T14:39:17.48076469Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 서울 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.484847093Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 부산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.486650894Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 인천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.488633896Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 대구 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.491292198Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 수원 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.492992099Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 부천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.494546201Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 김포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.496085002Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 이천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.497886803Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 원주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.499543204Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 목포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.501072806Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 세종 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.502759507Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 창원 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.504450708Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 제주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.505994709Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 울산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.507641011Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 삼척 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.509199012Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.510525313Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 평택 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.512070714Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 용인 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.513696115Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 강릉 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.515412917Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 대전 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.517720219Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 여수 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.51910992Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 의정부 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.520569721Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 진천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.522091722Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 경주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.523625923Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 통영 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.525773225Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 동해 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.527371926Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광명 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.529030027Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 남양주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.530923729Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 춘천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.53296643Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.534918132Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 청주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.536921234Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 포항 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.538513835Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 진주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.540231136Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 속초 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.541761037Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.544372139Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 성남 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.546718441Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.548526743Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 고양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.550704044Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안성 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.552528846Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 전주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.554487547Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 순천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.556095148Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안동 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.55797655Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 김해 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:39:17.560088851Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 서귀포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T14:42:17.25145985Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Revoke previously assigned partitions slack-retry-topic-0"}
{"@timestamp":"2025-08-02T14:42:17.25145965Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Revoke previously assigned partitions email-retry-topic-0"}
{"@timestamp":"2025-08-02T14:42:17.253355007Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: partitions revoked: [email-retry-topic-0]"}
{"@timestamp":"2025-08-02T14:42:17.253355007Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: partitions revoked: [slack-retry-topic-0]"}
{"@timestamp":"2025-08-02T14:42:17.25477915Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Member consumer-email-retry-group-1-71a64b06-33fe-4e83-98d2-da43d81d0574 sending LeaveGroup request to coordinator kafka:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics"}
{"@timestamp":"2025-08-02T14:42:17.25477935Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Member consumer-slack-retry-group-2-a1bb41b2-8e63-49ce-b529-222f177eb68b sending LeaveGroup request to coordinator kafka:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics"}
{"@timestamp":"2025-08-02T14:42:17.255995587Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.255995387Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.2564348Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.25675891Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.257070719Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Unsubscribed all topics or patterns and assigned partitions"}
{"@timestamp":"2025-08-02T14:42:17.257300326Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Unsubscribed all topics or patterns and assigned partitions"}
{"@timestamp":"2025-08-02T14:42:17.262874394Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.264330038Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.264693248Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.265204964Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T14:42:17.267036819Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics scheduler closed"}
{"@timestamp":"2025-08-02T14:42:17.267124922Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics scheduler closed"}
{"@timestamp":"2025-08-02T14:42:17.267818643Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Closing reporter org.apache.kafka.common.metrics.JmxReporter"}
{"@timestamp":"2025-08-02T14:42:17.268147852Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Closing reporter org.apache.kafka.common.metrics.JmxReporter"}
{"@timestamp":"2025-08-02T14:42:17.268872574Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics reporters closed"}
{"@timestamp":"2025-08-02T14:42:17.268995778Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics reporters closed"}
{"@timestamp":"2025-08-02T14:42:17.284511545Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"App info kafka.consumer for consumer-slack-retry-group-2 unregistered"}
{"@timestamp":"2025-08-02T14:42:17.285495675Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: Consumer stopped"}
{"@timestamp":"2025-08-02T14:42:17.285493975Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"App info kafka.consumer for consumer-email-retry-group-1 unregistered"}
{"@timestamp":"2025-08-02T14:42:17.2863483Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: Consumer stopped"}
{"@timestamp":"2025-08-02T14:42:19.35682667Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T14:42:19.359575553Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T14:42:21.268631306Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:12:20.540657459Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:12:20.624878375Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:12:20.626173588Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:12:22.074698909Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:12:22.076919758Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:12:22.108067352Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 8 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:12:22.934946971Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:12:22.937057618Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:12:23.400757947Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:12:23.455027656Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 511 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:12:23.467274129Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:12:23.467891843Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:12:23.474635593Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.478455578Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.479123593Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.479663905Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.480289619Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.483445689Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.484137104Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.484729118Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.485360532Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.485929644Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:12:23.490160639Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 21 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:12:25.433125819Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:12:25.451391126Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:12:25.457648265Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:12:25.458515885Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:12:25.614309355Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:12:25.616400602Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 4906 ms"}
{"@timestamp":"2025-08-02T15:12:26.992803362Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:12:27.195292272Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:12:27.206023011Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:12:28.216411253Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:12:28.313573891Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:12:28.828741291Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@6468a7b6"}
{"@timestamp":"2025-08-02T15:12:28.834457552Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:12:28.988599198Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:12:32.42311549Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:12:32.980234078Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:12:34.396479454Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:12:34.399307785Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:12:34.401769812Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:12:36.851595982Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:12:36.986554956Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:12:37.032806062Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:12:37.08941428Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:12:37.127104192Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:13:30.033941046Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:13:30.170067926Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:13:30.172514429Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:13:31.82423951Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:13:31.825899612Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:13:31.852479047Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:13:32.685831247Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:13:32.690393753Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:13:33.326267781Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:13:33.413820645Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 713 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:13:33.430351937Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:13:33.431267382Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:13:33.442020926Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.444974046Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.445923388Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.446831633Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.447742877Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.451240264Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.452186507Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.453398733Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.454608559Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.455519803Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:13:33.462491479Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 29 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:13:35.043354126Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:13:35.055731672Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:13:35.06002141Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:13:35.06083776Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:13:35.176579306Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:13:35.178619782Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 4852 ms"}
{"@timestamp":"2025-08-02T15:13:36.137706826Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:13:36.233594182Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:13:36.238112306Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:13:36.707732183Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:13:36.760841946Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:13:37.099057332Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@696b4a95"}
{"@timestamp":"2025-08-02T15:13:37.103662152Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:13:37.194367923Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:13:38.906713736Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:13:39.063495752Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:13:40.733718117Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:13:40.736791229Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:13:40.739296439Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:13:40.878787687Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:13:40.994963844Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:13:41.031147286Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:13:41.061235005Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:13:41.077439368Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:15:50.525676476Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:15:50.616543037Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:15:50.618252887Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:15:51.991021589Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:15:51.992816842Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:15:52.020505353Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 8 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:15:52.603510426Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:15:52.60534478Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:15:53.010696651Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:15:53.09535213Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 485 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:15:53.105796236Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:15:53.106383053Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:15:53.114017377Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.116233241Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.116971163Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.117698384Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.118437506Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.121547497Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.122421923Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.123336049Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.124467683Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.12575492Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:15:53.131387985Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:15:54.553508133Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:15:54.563256418Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:15:54.566272206Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:15:54.567317437Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:15:54.674840886Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:15:54.676630038Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 3978 ms"}
{"@timestamp":"2025-08-02T15:15:55.560836633Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:15:55.661231173Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:15:55.667843966Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:15:56.125420867Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:15:56.162794061Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:15:56.370303038Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@696b4a95"}
{"@timestamp":"2025-08-02T15:15:56.374742568Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:15:56.461002094Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:15:57.958836599Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:15:58.109288343Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:15:59.366438177Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:15:59.368373534Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:15:59.370435795Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:15:59.929495608Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:16:00.048834233Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:16:00.0781807Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:16:00.1052442Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:16:00.11811868Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:18:20.263627282Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:18:20.346619858Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:18:20.347869367Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:18:21.845770513Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:18:21.848098794Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:18:21.880233269Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 8 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:18:22.626234019Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:18:22.628238561Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:18:23.131948396Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:18:23.196939733Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 560 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:18:23.217716338Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:18:23.218455527Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:18:23.2306748Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.232945174Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.233595652Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.234259032Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.234787396Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.237382309Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.238144201Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.238747074Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.239239633Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.239776098Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:18:23.244158526Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:18:24.686313785Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:18:24.696538692Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:18:24.699729625Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:18:24.700386132Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:18:24.798248157Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:18:24.800069076Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 4375 ms"}
{"@timestamp":"2025-08-02T15:18:25.703669237Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:18:25.800295449Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:18:25.806934718Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:18:26.227723024Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:18:26.279259363Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:18:26.489210462Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@696b4a95"}
{"@timestamp":"2025-08-02T15:18:26.49190629Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:18:26.554874349Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:18:27.982568898Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:18:28.141677664Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:18:29.566622683Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:18:29.569794216Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:18:29.572847148Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:18:30.083653393Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:18:30.207143736Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:18:30.233393107Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:18:30.278562845Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:18:30.295591785Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:25:39.670757482Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:25:39.763258481Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:25:39.764853471Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:25:41.112399568Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:25:41.114091982Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:25:41.1416828Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 8 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:25:41.863811806Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:25:41.866285525Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:25:42.316246069Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:25:42.362608051Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 490 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:25:42.373483107Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:25:42.3739884Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:25:42.379744023Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.381640998Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.38223729Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.382774183Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.383340775Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.385675044Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.386411934Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.386973227Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.387654118Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.388299409Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:25:42.393154945Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 18 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:25:43.982659385Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:25:43.992489154Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:25:43.995481214Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:25:43.996128906Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:25:44.100378768Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:25:44.102238643Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 4242 ms"}
{"@timestamp":"2025-08-02T15:25:45.379186345Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:25:45.585916693Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:25:45.600638397Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:25:46.716855857Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:25:46.825590025Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:25:47.406402359Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@6232ffdb"}
{"@timestamp":"2025-08-02T15:25:47.415542507Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:25:47.563183978Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:25:51.389574278Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:25:51.585665834Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:25:53.046082931Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:25:53.048712349Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:25:53.051378467Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:25:55.306286256Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:25:55.447857435Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:25:55.494459057Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:25:55.549162836Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:25:55.575419517Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:30:41.069334277Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:30:41.180395713Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:30:41.182027025Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:30:43.061560464Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:30:43.064086883Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:30:43.098743144Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 11 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:30:44.165699713Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:30:44.168104331Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:30:44.805335625Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:30:44.867921195Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 691 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:30:44.881369997Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:30:44.881984001Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:30:44.889635759Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.891712474Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.892655281Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.893341587Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.894148193Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.897121015Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.897957721Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.898803028Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.899414032Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.900027037Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:30:44.904635972Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 22 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:30:47.044513948Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:30:47.077698825Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:30:47.083184954Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:30:47.084462384Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:30:47.330673048Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:30:47.335992473Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 6060 ms"}
{"@timestamp":"2025-08-02T15:30:49.51628532Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:30:49.692452444Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:30:49.701543657Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:30:50.728583303Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:30:50.82711221Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:30:51.327294721Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@696b4a95"}
{"@timestamp":"2025-08-02T15:30:51.331346016Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:30:51.485325221Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:30:53.34366373Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:30:53.51022653Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:30:54.933051441Z","level":"WARN","logger_name":"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext","message":"Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accommodationQueryService' defined in URL [jar:file:/app.jar!/BOOT-INF/classes!/com/example/Triple_clone/domain/accommodation/application/AccommodationQueryService.class]: Unsatisfied dependency expressed through constructor parameter 0: Error creating bean with name 'accommodationRepository' defined in com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Could not create query for public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); Reason: Failed to create query for method public abstract java.util.List com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository.readAllByLocal(java.lang.String); No property 'local' found for type 'Accommodation'"}
{"@timestamp":"2025-08-02T15:30:54.936045512Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:30:54.938667073Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:30:55.054194678Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
{"@timestamp":"2025-08-02T15:30:55.174578096Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Stopping service [Tomcat]"}
{"@timestamp":"2025-08-02T15:30:55.208673794Z","level":"INFO","logger_name":"org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger","message":"\n\nError starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled."}
{"@timestamp":"2025-08-02T15:30:55.238073482Z","level":"ERROR","logger_name":"org.springframework.boot.SpringApplication","message":"Application run failed"}
{"@timestamp":"2025-08-02T15:30:55.250158465Z","level":"WARN","logger_name":"com.example.Triple_clone.common.logging.SlackLogbackAppender","message":"Slack 전송 실패 (LogbackAppender 내부): Error creating bean with name 'mdcAsyncExecutor' defined in class path resource [com/example/Triple_clone/configuration/AsyncConfig.class]: BeanPostProcessor before instantiation of bean failed"}
{"@timestamp":"2025-08-02T15:33:48.218526026Z","level":"INFO","logger_name":"org.hibernate.validator.internal.util.Version","message":"HV000001: Hibernate Validator 8.0.1.Final"}
{"@timestamp":"2025-08-02T15:33:48.298276191Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Starting TripleCloneApplication v0.0.1-SNAPSHOT using Java 21.0.7 with PID 1 (/app.jar started by root in /)"}
{"@timestamp":"2025-08-02T15:33:48.300274915Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"No active profile set, falling back to 1 default profile: \"default\""}
{"@timestamp":"2025-08-02T15:33:49.844052703Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:33:49.846183729Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:33:49.877929713Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 9 ms. Found 0 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:33:50.490751732Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:33:50.492397452Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:33:50.851018704Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.RedisAccommodationRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository"}
{"@timestamp":"2025-08-02T15:33:50.940757281Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 443 ms. Found 10 JPA repository interfaces."}
{"@timestamp":"2025-08-02T15:33:50.957317609Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Multiple Spring Data modules found, entering strict repository configuration mode"}
{"@timestamp":"2025-08-02T15:33:50.958061224Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode."}
{"@timestamp":"2025-08-02T15:33:50.972616912Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.accommodation.infra.AccommodationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.978806134Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.member.infra.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.98061717Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.AdminNotificationSettingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.981734392Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.982796613Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.notification.infra.NotificationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.985973576Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.DetailPlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.986959896Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.plan.infra.PlanRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.98820552Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.recommend.infra.RecommendationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.989069638Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.report.infra.ReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.989814552Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.example.Triple_clone.domain.review.infra.ReviewRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository"}
{"@timestamp":"2025-08-02T15:33:50.996463084Z","level":"INFO","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","message":"Finished Spring Data repository scanning in 37 ms. Found 1 Redis repository interfaces."}
{"@timestamp":"2025-08-02T15:33:52.541605179Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat initialized with port(s): 8080 (http)"}
{"@timestamp":"2025-08-02T15:33:52.569606434Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Initializing ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:33:52.579188923Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardService","message":"Starting service [Tomcat]"}
{"@timestamp":"2025-08-02T15:33:52.580142942Z","level":"INFO","logger_name":"org.apache.catalina.core.StandardEngine","message":"Starting Servlet engine: [Apache Tomcat/10.1.15]"}
{"@timestamp":"2025-08-02T15:33:52.810778809Z","level":"INFO","logger_name":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]","message":"Initializing Spring embedded WebApplicationContext"}
{"@timestamp":"2025-08-02T15:33:52.812805149Z","level":"INFO","logger_name":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext","message":"Root WebApplicationContext: initialization completed in 4429 ms"}
{"@timestamp":"2025-08-02T15:33:54.904643869Z","level":"INFO","logger_name":"org.hibernate.jpa.internal.util.LogHelper","message":"HHH000204: Processing PersistenceUnitInfo [name: default]"}
{"@timestamp":"2025-08-02T15:33:55.103435106Z","level":"INFO","logger_name":"org.hibernate.Version","message":"HHH000412: Hibernate ORM core version 6.2.13.Final"}
{"@timestamp":"2025-08-02T15:33:55.116524865Z","level":"INFO","logger_name":"org.hibernate.cfg.Environment","message":"HHH000406: Using bytecode reflection optimizer"}
{"@timestamp":"2025-08-02T15:33:56.039692244Z","level":"INFO","logger_name":"org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo","message":"No LoadTimeWeaver setup: ignoring JPA class transformer"}
{"@timestamp":"2025-08-02T15:33:56.141160754Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Starting..."}
{"@timestamp":"2025-08-02T15:33:56.627985593Z","level":"INFO","logger_name":"com.zaxxer.hikari.pool.HikariPool","message":"HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@696b4a95"}
{"@timestamp":"2025-08-02T15:33:56.632601385Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Start completed."}
{"@timestamp":"2025-08-02T15:33:56.778120166Z","level":"WARN","logger_name":"org.hibernate.orm.deprecation","message":"HHH90000025: MySQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)"}
{"@timestamp":"2025-08-02T15:33:59.398843353Z","level":"INFO","logger_name":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator","message":"HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)"}
{"@timestamp":"2025-08-02T15:33:59.614590381Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:34:02.363411221Z","level":"WARN","logger_name":"org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration","message":"spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning"}
{"@timestamp":"2025-08-02T15:34:03.545195423Z","level":"INFO","logger_name":"org.springframework.boot.actuate.endpoint.web.EndpointLinksResolver","message":"Exposing 14 endpoint(s) beneath base path '/actuator'"}
{"@timestamp":"2025-08-02T15:34:03.707876254Z","level":"INFO","logger_name":"org.springframework.security.web.DefaultSecurityFilterChain","message":"Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@6207145c, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@2a259f6f, org.springframework.security.web.context.SecurityContextHolderFilter@1d1c63af, org.springframework.security.web.header.HeaderWriterFilter@773c7147, org.springframework.security.web.authentication.logout.LogoutFilter@6ff8e744, com.example.Triple_clone.common.auth.JwtAuthFilter@7ccf6114, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@3909a854, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@586486c, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3df3410a, org.springframework.security.web.session.SessionManagementFilter@578d472a, org.springframework.security.web.access.ExceptionTranslationFilter@5e7e7a7e, org.springframework.security.web.access.intercept.AuthorizationFilter@6a878778]"}
{"@timestamp":"2025-08-02T15:34:05.593423278Z","level":"INFO","logger_name":"org.apache.coyote.http11.Http11NioProtocol","message":"Starting ProtocolHandler [\"http-nio-8080\"]"}
{"@timestamp":"2025-08-02T15:34:05.69937477Z","level":"INFO","logger_name":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer","message":"Tomcat started on port(s): 8080 (http) with context path ''"}
{"@timestamp":"2025-08-02T15:34:05.805428264Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.ConsumerConfig","message":"ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = latest\n\tbootstrap.servers = [kafka:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-email-retry-group-1\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = email-retry-group\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer\n"}
{"@timestamp":"2025-08-02T15:34:06.171873489Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka version: 3.4.1"}
{"@timestamp":"2025-08-02T15:34:06.173952012Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka commitId: 8a516edc2755df89"}
{"@timestamp":"2025-08-02T15:34:06.174743221Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka startTimeMs: 1754148846163"}
{"@timestamp":"2025-08-02T15:34:06.23684902Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Subscribed to topic(s): email-retry-topic"}
{"@timestamp":"2025-08-02T15:34:06.265409541Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.ConsumerConfig","message":"ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = latest\n\tbootstrap.servers = [kafka:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-slack-retry-group-2\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = slack-retry-group\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer\n"}
{"@timestamp":"2025-08-02T15:34:06.282843838Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka version: 3.4.1"}
{"@timestamp":"2025-08-02T15:34:06.284309354Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka commitId: 8a516edc2755df89"}
{"@timestamp":"2025-08-02T15:34:06.285594669Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"Kafka startTimeMs: 1754148846282"}
{"@timestamp":"2025-08-02T15:34:06.320456961Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Subscribed to topic(s): slack-retry-topic"}
{"@timestamp":"2025-08-02T15:34:06.435231353Z","level":"INFO","logger_name":"com.example.Triple_clone.TripleCloneApplication","message":"Started TripleCloneApplication in 19.13 seconds (process running for 20.009)"}
{"@timestamp":"2025-08-02T15:34:06.462465059Z","level":"INFO","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"✅ Batch 프로세스 시작: 숙소 정보 크롤링","traceId":"3de712e6-8c8e-4207-b8a2-e6b5cef37298","uri":"scheduled::ScraperBatchService.scrapeAllLocations()","email":"system"}
{"@timestamp":"2025-08-02T15:34:07.215202419Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting the last seen epoch of partition email-retry-topic-0 to 0 since the associated topicId changed from null to mQdd2KszQ1eggDw7modFew"}
{"@timestamp":"2025-08-02T15:34:07.215192819Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting the last seen epoch of partition slack-retry-topic-0 to 0 since the associated topicId changed from null to HjUrRdwvQkK0Tx_sLZnRXQ"}
{"@timestamp":"2025-08-02T15:34:07.220858912Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Cluster ID: Ob-1HD5GQPC6lHr6Ghhp_A"}
{"@timestamp":"2025-08-02T15:34:07.221174011Z","level":"INFO","logger_name":"org.apache.kafka.clients.Metadata","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Cluster ID: Ob-1HD5GQPC6lHr6Ghhp_A"}
{"@timestamp":"2025-08-02T15:34:07.225146206Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)"}
{"@timestamp":"2025-08-02T15:34:07.226152404Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null)"}
{"@timestamp":"2025-08-02T15:34:07.2294995Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T15:34:07.2295821Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T15:34:07.285600424Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: need to re-join with the given member-id: consumer-email-retry-group-1-0a4fcd5d-7cb4-43c2-9ad0-92df3394c969"}
{"@timestamp":"2025-08-02T15:34:07.285600324Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: need to re-join with the given member-id: consumer-slack-retry-group-2-7021cb84-9c8d-49c6-80b7-bd3de8af86fd"}
{"@timestamp":"2025-08-02T15:34:07.287356522Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)"}
{"@timestamp":"2025-08-02T15:34:07.287452922Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)"}
{"@timestamp":"2025-08-02T15:34:07.287843121Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T15:34:07.288171121Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] (Re-)joining group"}
{"@timestamp":"2025-08-02T15:34:08.384732639Z","level":"INFO","logger_name":"com.example.Triple_clone.common.logging.MetricToInfluxJob","message":"✅ Batch 프로세스 종료: InfluxDB write","traceId":"0ae987ba-fed5-4ab8-a6a1-e04c916e75c0","uri":"scheduled::MetricToInfluxJob.reportMetrics()","email":"system"}
{"@timestamp":"2025-08-02T15:34:10.299486951Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Successfully joined group with generation Generation{generationId=5, memberId='consumer-slack-retry-group-2-7021cb84-9c8d-49c6-80b7-bd3de8af86fd', protocol='range'}"}
{"@timestamp":"2025-08-02T15:34:10.30065695Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Successfully joined group with generation Generation{generationId=5, memberId='consumer-email-retry-group-1-0a4fcd5d-7cb4-43c2-9ad0-92df3394c969', protocol='range'}"}
{"@timestamp":"2025-08-02T15:34:10.302720347Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Finished assignment for group at generation 5: {consumer-email-retry-group-1-0a4fcd5d-7cb4-43c2-9ad0-92df3394c969=Assignment(partitions=[email-retry-topic-0])}"}
{"@timestamp":"2025-08-02T15:34:10.302720247Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Finished assignment for group at generation 5: {consumer-slack-retry-group-2-7021cb84-9c8d-49c6-80b7-bd3de8af86fd=Assignment(partitions=[slack-retry-topic-0])}"}
{"@timestamp":"2025-08-02T15:34:10.31538243Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Successfully synced group in generation Generation{generationId=5, memberId='consumer-email-retry-group-1-0a4fcd5d-7cb4-43c2-9ad0-92df3394c969', protocol='range'}"}
{"@timestamp":"2025-08-02T15:34:10.31538233Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Successfully synced group in generation Generation{generationId=5, memberId='consumer-slack-retry-group-2-7021cb84-9c8d-49c6-80b7-bd3de8af86fd', protocol='range'}"}
{"@timestamp":"2025-08-02T15:34:10.316215029Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Notifying assignor about the new Assignment(partitions=[email-retry-topic-0])"}
{"@timestamp":"2025-08-02T15:34:10.316336228Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Notifying assignor about the new Assignment(partitions=[slack-retry-topic-0])"}
{"@timestamp":"2025-08-02T15:34:10.319103725Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Adding newly assigned partitions: email-retry-topic-0"}
{"@timestamp":"2025-08-02T15:34:10.319103625Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Adding newly assigned partitions: slack-retry-topic-0"}
{"@timestamp":"2025-08-02T15:34:10.333991405Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Setting offset for partition slack-retry-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}"}
{"@timestamp":"2025-08-02T15:34:10.333991405Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Setting offset for partition email-retry-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}"}
{"@timestamp":"2025-08-02T15:34:10.335457803Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: partitions assigned: [slack-retry-topic-0]"}
{"@timestamp":"2025-08-02T15:34:10.335518903Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: partitions assigned: [email-retry-topic-0]"}
{"@timestamp":"2025-08-02T15:34:15.099249409Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 대구 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.103029606Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 부산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.104545505Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 서울 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.106062504Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 인천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.107664902Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 대전 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.108942201Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 수원 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.110015101Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.1111847Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 성남 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.112249399Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 의정부 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.113164198Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 울산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.114439097Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광명 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.115661996Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안산 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.116847795Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.118166094Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 남양주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.119317493Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 고양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.120522193Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 평택 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.121703692Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 부천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.12328509Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 춘천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.133372383Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 용인 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.134913082Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안성 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.136429581Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 광양 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.13765228Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 강릉 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.138847979Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 전주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.140013278Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 청주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.141043677Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 여수 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.142342976Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 순천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.143525875Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 포항 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.144824174Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 진천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.146148773Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 안동 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.147322772Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 김포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.148713871Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 경주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.15003537Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 김해 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.151507069Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 진주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.153210768Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 통영 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.154986266Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 이천 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.156322765Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 서귀포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.157579764Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 속초 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.158811964Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 동해 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.160105363Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 원주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.161565561Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 목포 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.16304296Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 세종 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.164300459Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 창원 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.165620358Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 제주 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:34:15.167614057Z","level":"ERROR","logger_name":"com.example.Triple_clone.batch.ScraperBatchService","message":"❌ Batch 프로세스 실패 - 삼척 숙소 정보 크롤링: Failed to resolve 'fastapi-container' [A(1)] after 2 queries "}
{"@timestamp":"2025-08-02T15:36:11.280809539Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Revoke previously assigned partitions slack-retry-topic-0"}
{"@timestamp":"2025-08-02T15:36:11.281147946Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Revoke previously assigned partitions email-retry-topic-0"}
{"@timestamp":"2025-08-02T15:36:11.283910805Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: partitions revoked: [slack-retry-topic-0]"}
{"@timestamp":"2025-08-02T15:36:11.283966506Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: partitions revoked: [email-retry-topic-0]"}
{"@timestamp":"2025-08-02T15:36:11.286215053Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Member consumer-slack-retry-group-2-7021cb84-9c8d-49c6-80b7-bd3de8af86fd sending LeaveGroup request to coordinator kafka:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics"}
{"@timestamp":"2025-08-02T15:36:11.286216953Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Member consumer-email-retry-group-1-0a4fcd5d-7cb4-43c2-9ad0-92df3394c969 sending LeaveGroup request to coordinator kafka:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics"}
{"@timestamp":"2025-08-02T15:36:11.293377804Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.296922878Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.303925626Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.304575839Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.304972548Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Unsubscribed all topics or patterns and assigned partitions"}
{"@timestamp":"2025-08-02T15:36:11.305196353Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.KafkaConsumer","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Unsubscribed all topics or patterns and assigned partitions"}
{"@timestamp":"2025-08-02T15:36:11.315084461Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.316031781Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-email-retry-group-1, groupId=email-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.318954042Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics scheduler closed"}
{"@timestamp":"2025-08-02T15:36:11.319598256Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Closing reporter org.apache.kafka.common.metrics.JmxReporter"}
{"@timestamp":"2025-08-02T15:36:11.32027517Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics reporters closed"}
{"@timestamp":"2025-08-02T15:36:11.320806281Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Resetting generation and member id due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.322439315Z","level":"INFO","logger_name":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator","message":"[Consumer clientId=consumer-slack-retry-group-2, groupId=slack-retry-group] Request joining group due to: consumer pro-actively leaving the group"}
{"@timestamp":"2025-08-02T15:36:11.326238495Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics scheduler closed"}
{"@timestamp":"2025-08-02T15:36:11.326844708Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Closing reporter org.apache.kafka.common.metrics.JmxReporter"}
{"@timestamp":"2025-08-02T15:36:11.327768428Z","level":"INFO","logger_name":"org.apache.kafka.common.metrics.Metrics","message":"Metrics reporters closed"}
{"@timestamp":"2025-08-02T15:36:11.349677489Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"App info kafka.consumer for consumer-email-retry-group-1 unregistered"}
{"@timestamp":"2025-08-02T15:36:11.35260265Z","level":"INFO","logger_name":"org.apache.kafka.common.utils.AppInfoParser","message":"App info kafka.consumer for consumer-slack-retry-group-2 unregistered"}
{"@timestamp":"2025-08-02T15:36:11.354561491Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"slack-retry-group: Consumer stopped"}
{"@timestamp":"2025-08-02T15:36:11.355086503Z","level":"INFO","logger_name":"org.springframework.kafka.listener.KafkaMessageListenerContainer","message":"email-retry-group: Consumer stopped"}
{"@timestamp":"2025-08-02T15:36:13.616316895Z","level":"INFO","logger_name":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean","message":"Closing JPA EntityManagerFactory for persistence unit 'default'"}
{"@timestamp":"2025-08-02T15:36:13.620760688Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown initiated..."}
{"@timestamp":"2025-08-02T15:36:14.292152784Z","level":"INFO","logger_name":"com.zaxxer.hikari.HikariDataSource","message":"HikariPool-1 - Shutdown completed."}
